{"ast":null,"code":"// AI Service for handling API requests to AI models\n\n/**\n * Sends a message to the AI model and returns the response\n * @param {Array} chatHistory - The chat history between user and AI\n * @param {string} userInput - The current user message\n * @param {boolean} isFirstMessage - Whether this is the first message in the conversation\n * @returns {Promise<string>} - The AI's response text\n */\nexport const getAIResponse = async (chatHistory, userInput, isFirstMessage = false) => {\n  try {\n    // Prepare the chat history for the API payload\n    let apiChatHistory = chatHistory.map(msg => ({\n      role: msg.role === 'user' ? 'user' : 'model',\n      parts: [{\n        text: msg.text\n      }]\n    }));\n\n    // Add the current user message to the API chat history\n    apiChatHistory.push({\n      role: 'user',\n      parts: [{\n        text: userInput\n      }]\n    });\n\n    // Define the initial prompt for the AI to set its persona\n    const initialPrompt = {\n      role: \"user\",\n      parts: [{\n        text: \"You are a helpful and patient tech support agent. Your goal is to assist the user in troubleshooting common technical issues. Provide clear, step-by-step instructions and ask clarifying questions when needed. Keep your responses professional and focused on problem-solving. This is for training purposes, so be thorough in your explanations. Start by asking the user what problem they are experiencing.\"\n      }]\n    };\n\n    // If it's the very first message, include the initial persona prompt\n    const payloadContents = isFirstMessage ? [initialPrompt, {\n      role: \"user\",\n      parts: [{\n        text: userInput\n      }]\n    }] : apiChatHistory;\n    const payload = {\n      contents: payloadContents,\n      generationConfig: {\n        temperature: 0.7,\n        topK: 40,\n        topP: 0.95,\n        maxOutputTokens: 500\n      }\n    };\n\n    // Replace with your actual API key or environment variable\n    // For production, use environment variables (process.env.REACT_APP_AI_API_KEY)\n    const apiKey = process.env.REACT_APP_GEMINI_API_KEY || \"\";\n    const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;\n    const response = await fetch(apiUrl, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify(payload)\n    });\n    if (!response.ok) {\n      throw new Error(`API request failed with status: ${response.status}`);\n    }\n    const result = await response.json();\n    if (result.candidates && result.candidates.length > 0 && result.candidates[0].content && result.candidates[0].content.parts && result.candidates[0].content.parts.length > 0) {\n      return result.candidates[0].content.parts[0].text;\n    } else {\n      console.error('Unexpected API response structure:', result);\n      throw new Error('Invalid response format from AI service');\n    }\n  } catch (error) {\n    console.error('Error in AI service:', error);\n    throw error; // Re-throw to handle in the component\n  }\n};\n\n/**\n * Alternative API for AI responses using OpenAI\n * @param {Array} chatHistory - The chat history between user and AI\n * @param {string} userInput - The current user message\n * @returns {Promise<string>} - The AI's response text\n */\nexport const getOpenAIResponse = async (chatHistory, userInput) => {\n  try {\n    // Format messages for OpenAI API\n    const messages = [\n    // System message to set the AI's behavior\n    {\n      role: \"system\",\n      content: \"You are a helpful and patient tech support agent. Your goal is to assist the user in troubleshooting common technical issues. Provide clear, step-by-step instructions and ask clarifying questions when needed. Keep your responses professional and focused on problem-solving.\"\n    },\n    // Convert chat history to OpenAI format\n    ...chatHistory.map(msg => ({\n      role: msg.role === 'model' ? 'assistant' : 'user',\n      content: msg.text\n    })),\n    // Add current user message\n    {\n      role: \"user\",\n      content: userInput\n    }];\n\n    // Replace with your actual OpenAI API key\n    const apiKey = process.env.REACT_APP_OPENAI_API_KEY || \"\";\n    const response = await fetch('https://api.openai.com/v1/chat/completions', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${apiKey}`\n      },\n      body: JSON.stringify({\n        model: \"gpt-3.5-turbo\",\n        messages: messages,\n        temperature: 0.7,\n        max_tokens: 500\n      })\n    });\n    if (!response.ok) {\n      throw new Error(`OpenAI API request failed with status: ${response.status}`);\n    }\n    const data = await response.json();\n    if (data.choices && data.choices.length > 0 && data.choices[0].message) {\n      return data.choices[0].message.content;\n    } else {\n      console.error('Unexpected OpenAI API response structure:', data);\n      throw new Error('Invalid response format from OpenAI service');\n    }\n  } catch (error) {\n    console.error('Error in OpenAI service:', error);\n    throw error;\n  }\n};","map":{"version":3,"names":["getAIResponse","chatHistory","userInput","isFirstMessage","apiChatHistory","map","msg","role","parts","text","push","initialPrompt","payloadContents","payload","contents","generationConfig","temperature","topK","topP","maxOutputTokens","apiKey","process","env","REACT_APP_GEMINI_API_KEY","apiUrl","response","fetch","method","headers","body","JSON","stringify","ok","Error","status","result","json","candidates","length","content","console","error","getOpenAIResponse","messages","REACT_APP_OPENAI_API_KEY","model","max_tokens","data","choices","message"],"sources":["C:/Users/HP/AiAgent/src/services/aiService.js"],"sourcesContent":["// AI Service for handling API requests to AI models\n\n/**\n * Sends a message to the AI model and returns the response\n * @param {Array} chatHistory - The chat history between user and AI\n * @param {string} userInput - The current user message\n * @param {boolean} isFirstMessage - Whether this is the first message in the conversation\n * @returns {Promise<string>} - The AI's response text\n */\nexport const getAIResponse = async (chatHistory, userInput, isFirstMessage = false) => {\n  try {\n    // Prepare the chat history for the API payload\n    let apiChatHistory = chatHistory.map(msg => ({\n      role: msg.role === 'user' ? 'user' : 'model',\n      parts: [{ text: msg.text }]\n    }));\n\n    // Add the current user message to the API chat history\n    apiChatHistory.push({ role: 'user', parts: [{ text: userInput }] });\n\n    // Define the initial prompt for the AI to set its persona\n    const initialPrompt = {\n      role: \"user\",\n      parts: [{ text: \"You are a helpful and patient tech support agent. Your goal is to assist the user in troubleshooting common technical issues. Provide clear, step-by-step instructions and ask clarifying questions when needed. Keep your responses professional and focused on problem-solving. This is for training purposes, so be thorough in your explanations. Start by asking the user what problem they are experiencing.\" }]\n    };\n\n    // If it's the very first message, include the initial persona prompt\n    const payloadContents = isFirstMessage\n      ? [initialPrompt, { role: \"user\", parts: [{ text: userInput }] }]\n      : apiChatHistory;\n\n    const payload = {\n      contents: payloadContents,\n      generationConfig: {\n        temperature: 0.7,\n        topK: 40,\n        topP: 0.95,\n        maxOutputTokens: 500\n      }\n    };\n\n    // Replace with your actual API key or environment variable\n    // For production, use environment variables (process.env.REACT_APP_AI_API_KEY)\n    const apiKey = process.env.REACT_APP_GEMINI_API_KEY || \"\";\n    const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;\n\n    const response = await fetch(apiUrl, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify(payload)\n    });\n\n    if (!response.ok) {\n      throw new Error(`API request failed with status: ${response.status}`);\n    }\n\n    const result = await response.json();\n\n    if (result.candidates && \n        result.candidates.length > 0 &&\n        result.candidates[0].content && \n        result.candidates[0].content.parts &&\n        result.candidates[0].content.parts.length > 0) {\n      return result.candidates[0].content.parts[0].text;\n    } else {\n      console.error('Unexpected API response structure:', result);\n      throw new Error('Invalid response format from AI service');\n    }\n  } catch (error) {\n    console.error('Error in AI service:', error);\n    throw error; // Re-throw to handle in the component\n  }\n};\n\n/**\n * Alternative API for AI responses using OpenAI\n * @param {Array} chatHistory - The chat history between user and AI\n * @param {string} userInput - The current user message\n * @returns {Promise<string>} - The AI's response text\n */\nexport const getOpenAIResponse = async (chatHistory, userInput) => {\n  try {\n    // Format messages for OpenAI API\n    const messages = [\n      // System message to set the AI's behavior\n      { \n        role: \"system\", \n        content: \"You are a helpful and patient tech support agent. Your goal is to assist the user in troubleshooting common technical issues. Provide clear, step-by-step instructions and ask clarifying questions when needed. Keep your responses professional and focused on problem-solving.\"\n      },\n      // Convert chat history to OpenAI format\n      ...chatHistory.map(msg => ({\n        role: msg.role === 'model' ? 'assistant' : 'user',\n        content: msg.text\n      })),\n      // Add current user message\n      { role: \"user\", content: userInput }\n    ];\n\n    // Replace with your actual OpenAI API key\n    const apiKey = process.env.REACT_APP_OPENAI_API_KEY || \"\";\n    \n    const response = await fetch('https://api.openai.com/v1/chat/completions', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${apiKey}`\n      },\n      body: JSON.stringify({\n        model: \"gpt-3.5-turbo\",\n        messages: messages,\n        temperature: 0.7,\n        max_tokens: 500\n      })\n    });\n\n    if (!response.ok) {\n      throw new Error(`OpenAI API request failed with status: ${response.status}`);\n    }\n\n    const data = await response.json();\n    \n    if (data.choices && data.choices.length > 0 && data.choices[0].message) {\n      return data.choices[0].message.content;\n    } else {\n      console.error('Unexpected OpenAI API response structure:', data);\n      throw new Error('Invalid response format from OpenAI service');\n    }\n  } catch (error) {\n    console.error('Error in OpenAI service:', error);\n    throw error;\n  }\n};"],"mappings":"AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMA,aAAa,GAAG,MAAAA,CAAOC,WAAW,EAAEC,SAAS,EAAEC,cAAc,GAAG,KAAK,KAAK;EACrF,IAAI;IACF;IACA,IAAIC,cAAc,GAAGH,WAAW,CAACI,GAAG,CAACC,GAAG,KAAK;MAC3CC,IAAI,EAAED,GAAG,CAACC,IAAI,KAAK,MAAM,GAAG,MAAM,GAAG,OAAO;MAC5CC,KAAK,EAAE,CAAC;QAAEC,IAAI,EAAEH,GAAG,CAACG;MAAK,CAAC;IAC5B,CAAC,CAAC,CAAC;;IAEH;IACAL,cAAc,CAACM,IAAI,CAAC;MAAEH,IAAI,EAAE,MAAM;MAAEC,KAAK,EAAE,CAAC;QAAEC,IAAI,EAAEP;MAAU,CAAC;IAAE,CAAC,CAAC;;IAEnE;IACA,MAAMS,aAAa,GAAG;MACpBJ,IAAI,EAAE,MAAM;MACZC,KAAK,EAAE,CAAC;QAAEC,IAAI,EAAE;MAAqZ,CAAC;IACxa,CAAC;;IAED;IACA,MAAMG,eAAe,GAAGT,cAAc,GAClC,CAACQ,aAAa,EAAE;MAAEJ,IAAI,EAAE,MAAM;MAAEC,KAAK,EAAE,CAAC;QAAEC,IAAI,EAAEP;MAAU,CAAC;IAAE,CAAC,CAAC,GAC/DE,cAAc;IAElB,MAAMS,OAAO,GAAG;MACdC,QAAQ,EAAEF,eAAe;MACzBG,gBAAgB,EAAE;QAChBC,WAAW,EAAE,GAAG;QAChBC,IAAI,EAAE,EAAE;QACRC,IAAI,EAAE,IAAI;QACVC,eAAe,EAAE;MACnB;IACF,CAAC;;IAED;IACA;IACA,MAAMC,MAAM,GAAGC,OAAO,CAACC,GAAG,CAACC,wBAAwB,IAAI,EAAE;IACzD,MAAMC,MAAM,GAAG,gGAAgGJ,MAAM,EAAE;IAEvH,MAAMK,QAAQ,GAAG,MAAMC,KAAK,CAACF,MAAM,EAAE;MACnCG,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QAAE,cAAc,EAAE;MAAmB,CAAC;MAC/CC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAClB,OAAO;IAC9B,CAAC,CAAC;IAEF,IAAI,CAACY,QAAQ,CAACO,EAAE,EAAE;MAChB,MAAM,IAAIC,KAAK,CAAC,mCAAmCR,QAAQ,CAACS,MAAM,EAAE,CAAC;IACvE;IAEA,MAAMC,MAAM,GAAG,MAAMV,QAAQ,CAACW,IAAI,CAAC,CAAC;IAEpC,IAAID,MAAM,CAACE,UAAU,IACjBF,MAAM,CAACE,UAAU,CAACC,MAAM,GAAG,CAAC,IAC5BH,MAAM,CAACE,UAAU,CAAC,CAAC,CAAC,CAACE,OAAO,IAC5BJ,MAAM,CAACE,UAAU,CAAC,CAAC,CAAC,CAACE,OAAO,CAAC/B,KAAK,IAClC2B,MAAM,CAACE,UAAU,CAAC,CAAC,CAAC,CAACE,OAAO,CAAC/B,KAAK,CAAC8B,MAAM,GAAG,CAAC,EAAE;MACjD,OAAOH,MAAM,CAACE,UAAU,CAAC,CAAC,CAAC,CAACE,OAAO,CAAC/B,KAAK,CAAC,CAAC,CAAC,CAACC,IAAI;IACnD,CAAC,MAAM;MACL+B,OAAO,CAACC,KAAK,CAAC,oCAAoC,EAAEN,MAAM,CAAC;MAC3D,MAAM,IAAIF,KAAK,CAAC,yCAAyC,CAAC;IAC5D;EACF,CAAC,CAAC,OAAOQ,KAAK,EAAE;IACdD,OAAO,CAACC,KAAK,CAAC,sBAAsB,EAAEA,KAAK,CAAC;IAC5C,MAAMA,KAAK,CAAC,CAAC;EACf;AACF,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,iBAAiB,GAAG,MAAAA,CAAOzC,WAAW,EAAEC,SAAS,KAAK;EACjE,IAAI;IACF;IACA,MAAMyC,QAAQ,GAAG;IACf;IACA;MACEpC,IAAI,EAAE,QAAQ;MACdgC,OAAO,EAAE;IACX,CAAC;IACD;IACA,GAAGtC,WAAW,CAACI,GAAG,CAACC,GAAG,KAAK;MACzBC,IAAI,EAAED,GAAG,CAACC,IAAI,KAAK,OAAO,GAAG,WAAW,GAAG,MAAM;MACjDgC,OAAO,EAAEjC,GAAG,CAACG;IACf,CAAC,CAAC,CAAC;IACH;IACA;MAAEF,IAAI,EAAE,MAAM;MAAEgC,OAAO,EAAErC;IAAU,CAAC,CACrC;;IAED;IACA,MAAMkB,MAAM,GAAGC,OAAO,CAACC,GAAG,CAACsB,wBAAwB,IAAI,EAAE;IAEzD,MAAMnB,QAAQ,GAAG,MAAMC,KAAK,CAAC,4CAA4C,EAAE;MACzEC,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACP,cAAc,EAAE,kBAAkB;QAClC,eAAe,EAAE,UAAUR,MAAM;MACnC,CAAC;MACDS,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnBc,KAAK,EAAE,eAAe;QACtBF,QAAQ,EAAEA,QAAQ;QAClB3B,WAAW,EAAE,GAAG;QAChB8B,UAAU,EAAE;MACd,CAAC;IACH,CAAC,CAAC;IAEF,IAAI,CAACrB,QAAQ,CAACO,EAAE,EAAE;MAChB,MAAM,IAAIC,KAAK,CAAC,0CAA0CR,QAAQ,CAACS,MAAM,EAAE,CAAC;IAC9E;IAEA,MAAMa,IAAI,GAAG,MAAMtB,QAAQ,CAACW,IAAI,CAAC,CAAC;IAElC,IAAIW,IAAI,CAACC,OAAO,IAAID,IAAI,CAACC,OAAO,CAACV,MAAM,GAAG,CAAC,IAAIS,IAAI,CAACC,OAAO,CAAC,CAAC,CAAC,CAACC,OAAO,EAAE;MACtE,OAAOF,IAAI,CAACC,OAAO,CAAC,CAAC,CAAC,CAACC,OAAO,CAACV,OAAO;IACxC,CAAC,MAAM;MACLC,OAAO,CAACC,KAAK,CAAC,2CAA2C,EAAEM,IAAI,CAAC;MAChE,MAAM,IAAId,KAAK,CAAC,6CAA6C,CAAC;IAChE;EACF,CAAC,CAAC,OAAOQ,KAAK,EAAE;IACdD,OAAO,CAACC,KAAK,CAAC,0BAA0B,EAAEA,KAAK,CAAC;IAChD,MAAMA,KAAK;EACb;AACF,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}